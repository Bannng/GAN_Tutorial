{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGAN (MNIST).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"T8134NSeyqDE","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torchvision\n","import torch.nn as nn\n","from torchvision import transforms, datasets, models\n","from torchvision.utils import save_image\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KQ-MyM1JzCUq","colab_type":"code","colab":{}},"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EB_VlfB5zCWx","colab_type":"code","colab":{}},"cell_type":"code","source":["learning_rate= 2e-4\n","batch_size = 100\n","num_epochs = 30"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PGFIBFE9zCZJ","colab_type":"code","colab":{}},"cell_type":"code","source":["sample_dir = 'samples'\n","\n","if not os.path.exists(sample_dir):\n","  os.makedirs(sample_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wWY-chZjzCbj","colab_type":"code","colab":{}},"cell_type":"code","source":["transform = transforms.Compose([transforms.ToTensor()])\n","\n","dataset = datasets.MNIST(root='../../data/', train=True, transform=transform, download=True)\n","data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z90tJiRBzCd5","colab_type":"code","colab":{}},"cell_type":"code","source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.conv = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False), \n","                                nn.BatchNorm2d(64), # (n, 64, 14, 14)\n","                                nn.ReLU(True),\n","                                nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n","                                nn.BatchNorm2d(128), # (n, 128, 7, 7)\n","                                nn.ReLU(True),\n","                                nn.Conv2d(128, 256, kernel_size =3, stride=2, padding=1, bias=False),\n","                                nn.BatchNorm2d(256), # (n, 256, 4, 4)\n","                                nn.ReLU(True),\n","                                nn.AvgPool2d(4))\n","    \n","    self.fc = nn.Sequential(nn.Linear(256,1),\n","                            nn.Sigmoid())\n","    \n","  def forward(self, x):\n","    out = self.conv(x)\n","    out = out.view(out.size(0), -1)\n","    out = self.fc(out)\n","    \n","    return out\n","  \n","  \n","class Generator(nn.Module):\n","  def __init__(self):\n","    super(Generator, self).__init__()\n","    \n","    self.layer1 = nn.Sequential(nn.Linear(64, 256*4*4))\n","    \n","    self.convT = nn.Sequential(nn.ConvTranspose2d(256, 128, 4, 1, 0), # (n, 128, 7, 7)\n","                              nn.BatchNorm2d(128),\n","                              nn.LeakyReLU(0.2, True),\n","                              nn.ConvTranspose2d(128, 64, 4, 2, 1),  # (n, 64, 14, 14)\n","                              nn.BatchNorm2d(64),\n","                              nn.LeakyReLU(0.2, True),\n","                              nn.ConvTranspose2d(64, 1, 4, 2, 1),    # (n, 1, 28, 28)\n","                              nn.Tanh())\n","    \n","  def forward(self, x):\n","    out = self.layer1(x)\n","    \n","    out = out.view(out.size(0), 256, 4, 4)\n","    out = self.convT(out)\n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cZDOIj-6zCgY","colab_type":"code","colab":{}},"cell_type":"code","source":["D = Discriminator().to(device)\n","G = Generator().to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nkusPNH0zClM","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.BCELoss()\n","d_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate)\n","g_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate)\n","\n","def zero_grad():\n","  d_optimizer.zero_grad()\n","  g_optimizer.zero_grad()\n","  \n","def norm(images):\n","  return images*2 - 1\n","  \n","def denorm(images):\n","  images = (images+1) / 2\n","  return images.clamp(0,1)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VJvf7T8QzCni","colab_type":"code","outputId":"95507afb-a1e0-4ec8-f27a-dbad687c4fed","executionInfo":{"status":"error","timestamp":1552415121396,"user_tz":-540,"elapsed":2087652,"user":{"displayName":"이종민","photoUrl":"","userId":"09967794706452346719"}},"colab":{"base_uri":"https://localhost:8080/","height":3360}},"cell_type":"code","source":["for epoch in range(num_epochs):\n","  for i, (images, _) in enumerate(data_loader):\n","    images = images.to(device)\n","    images = norm(images)\n","    \n","    real_labels = torch.ones(images.size(0), 1).to(device)\n","    fake_labels = torch.zeros(images.size(0), 1).to(device)\n","    #===================================================\n","    #                 Train Discriminator\n","    # ==================================================\n","    outputs = D(images)\n","    d_loss_real = criterion(outputs, real_labels)\n","    \n","    z = torch.randn(images.size(0), 64).to(device)\n","    fake_image = G(z)\n","    outputs = D(fake_image)\n","    d_loss_fake = criterion(outputs, fake_labels)\n","    \n","    \n","    d_loss = d_loss_real + d_loss_fake\n","    \n","    zero_grad()\n","    d_loss.backward()\n","    d_optimizer.step()\n","    \n","    #===================================================\n","    #                 Train Generator\n","    # ==================================================\n","    z = torch.randn(images.size(0), 64).to(device)\n","    fake_image = G(z)\n","    outputs_fake = D(fake_image)\n","    g_loss = criterion(outputs_fake, real_labels)\n","    \n","    zero_grad()\n","    g_loss.backward()\n","    g_optimizer.step()\n","    \n","    \n","    if (i+1) % 200 == 0:\n","      print('Epoch [{}/{}], Step [{}/{}], d_loss [{:.4f} : {:.4f}], g_loss : {:.4f}'\n","            .format(epoch, num_epochs, i+1, len(data_loader), d_loss_real.item(), d_loss_fake.item(), g_loss.item()))\n","\n","    \n","  fake_image = fake_image.view(fake_image.size(0), 1, 28, 28)\n","  save_image(denorm(fake_image), os.path.join(sample_dir, 'fake_images={}.png'.format(str(epoch).zfill(3))))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [0/1000], Step [200/600], d_loss [0.0395 : 0.0519], g_loss : 3.3601\n","Epoch [0/1000], Step [400/600], d_loss [0.0277 : 0.0739], g_loss : 3.3675\n","Epoch [0/1000], Step [600/600], d_loss [0.0212 : 0.0197], g_loss : 4.5442\n","Epoch [1/1000], Step [200/600], d_loss [0.0642 : 0.0803], g_loss : 2.9044\n","Epoch [1/1000], Step [400/600], d_loss [0.0309 : 0.0326], g_loss : 4.3790\n","Epoch [1/1000], Step [600/600], d_loss [0.0332 : 0.0674], g_loss : 2.9637\n","Epoch [2/1000], Step [200/600], d_loss [0.0271 : 0.0775], g_loss : 3.4714\n","Epoch [2/1000], Step [400/600], d_loss [0.0333 : 0.0618], g_loss : 3.3065\n","Epoch [2/1000], Step [600/600], d_loss [0.0266 : 0.0414], g_loss : 2.9159\n","Epoch [3/1000], Step [200/600], d_loss [0.0647 : 0.0069], g_loss : 5.2051\n","Epoch [3/1000], Step [400/600], d_loss [0.0616 : 0.0547], g_loss : 3.3958\n","Epoch [3/1000], Step [600/600], d_loss [0.0413 : 0.0493], g_loss : 3.8480\n","Epoch [4/1000], Step [200/600], d_loss [0.4211 : 0.0882], g_loss : 2.1586\n","Epoch [4/1000], Step [400/600], d_loss [0.0709 : 0.0380], g_loss : 3.7912\n","Epoch [4/1000], Step [600/600], d_loss [0.0378 : 0.0322], g_loss : 3.6404\n","Epoch [5/1000], Step [200/600], d_loss [0.0602 : 0.0743], g_loss : 2.4635\n","Epoch [5/1000], Step [400/600], d_loss [0.1352 : 0.0199], g_loss : 3.9917\n","Epoch [5/1000], Step [600/600], d_loss [0.0607 : 0.0368], g_loss : 4.0535\n","Epoch [6/1000], Step [200/600], d_loss [0.5226 : 0.0053], g_loss : 2.6301\n","Epoch [6/1000], Step [400/600], d_loss [0.0150 : 0.1304], g_loss : 2.7912\n","Epoch [6/1000], Step [600/600], d_loss [0.0239 : 0.0045], g_loss : 5.8461\n","Epoch [7/1000], Step [200/600], d_loss [0.0079 : 0.0196], g_loss : 4.4748\n","Epoch [7/1000], Step [400/600], d_loss [0.0619 : 0.0203], g_loss : 2.9095\n","Epoch [7/1000], Step [600/600], d_loss [0.0478 : 0.0429], g_loss : 4.5984\n","Epoch [8/1000], Step [200/600], d_loss [0.0913 : 0.0059], g_loss : 5.2528\n","Epoch [8/1000], Step [400/600], d_loss [0.0137 : 0.0408], g_loss : 3.0575\n","Epoch [8/1000], Step [600/600], d_loss [0.0292 : 0.0081], g_loss : 4.9021\n","Epoch [9/1000], Step [200/600], d_loss [0.0291 : 0.0127], g_loss : 4.5133\n","Epoch [9/1000], Step [400/600], d_loss [0.0065 : 0.0109], g_loss : 4.2513\n","Epoch [9/1000], Step [600/600], d_loss [0.0099 : 0.0094], g_loss : 3.9495\n","Epoch [10/1000], Step [200/600], d_loss [0.2400 : 0.1238], g_loss : 3.0614\n","Epoch [10/1000], Step [400/600], d_loss [0.0724 : 0.0132], g_loss : 4.6433\n","Epoch [10/1000], Step [600/600], d_loss [0.0273 : 0.0408], g_loss : 2.6365\n","Epoch [11/1000], Step [200/600], d_loss [0.0230 : 0.0030], g_loss : 4.4569\n","Epoch [11/1000], Step [400/600], d_loss [0.0066 : 0.0787], g_loss : 3.1719\n","Epoch [11/1000], Step [600/600], d_loss [0.0046 : 0.0053], g_loss : 5.6252\n","Epoch [12/1000], Step [200/600], d_loss [0.1173 : 0.1059], g_loss : 1.9561\n","Epoch [12/1000], Step [400/600], d_loss [0.0036 : 0.0610], g_loss : 4.2658\n","Epoch [12/1000], Step [600/600], d_loss [0.0256 : 0.1152], g_loss : 3.7149\n","Epoch [13/1000], Step [200/600], d_loss [0.0025 : 0.0068], g_loss : 4.5343\n","Epoch [13/1000], Step [400/600], d_loss [0.0261 : 0.0086], g_loss : 6.0911\n","Epoch [13/1000], Step [600/600], d_loss [0.0126 : 0.0133], g_loss : 4.9570\n","Epoch [14/1000], Step [200/600], d_loss [0.0097 : 0.0333], g_loss : 4.0319\n","Epoch [14/1000], Step [400/600], d_loss [0.0041 : 0.0121], g_loss : 5.6999\n","Epoch [14/1000], Step [600/600], d_loss [0.0124 : 0.0130], g_loss : 5.3484\n","Epoch [15/1000], Step [200/600], d_loss [0.0080 : 0.0053], g_loss : 6.1390\n","Epoch [15/1000], Step [400/600], d_loss [0.0034 : 0.0044], g_loss : 6.3131\n","Epoch [15/1000], Step [600/600], d_loss [0.0214 : 0.0096], g_loss : 5.3642\n","Epoch [16/1000], Step [200/600], d_loss [0.0136 : 0.0023], g_loss : 5.9828\n","Epoch [16/1000], Step [400/600], d_loss [0.0222 : 0.0652], g_loss : 3.8744\n","Epoch [16/1000], Step [600/600], d_loss [0.0111 : 0.0029], g_loss : 3.4157\n","Epoch [17/1000], Step [200/600], d_loss [0.0164 : 0.0106], g_loss : 5.2484\n","Epoch [17/1000], Step [400/600], d_loss [0.0140 : 0.0030], g_loss : 5.0411\n","Epoch [17/1000], Step [600/600], d_loss [0.0046 : 0.0077], g_loss : 6.4094\n","Epoch [18/1000], Step [200/600], d_loss [0.0044 : 0.0090], g_loss : 6.2368\n","Epoch [18/1000], Step [400/600], d_loss [0.0323 : 0.0008], g_loss : 5.2966\n","Epoch [18/1000], Step [600/600], d_loss [0.0647 : 0.0009], g_loss : 5.7165\n","Epoch [19/1000], Step [200/600], d_loss [0.0008 : 0.0132], g_loss : 5.2662\n","Epoch [19/1000], Step [400/600], d_loss [0.0059 : 0.0041], g_loss : 6.5463\n","Epoch [19/1000], Step [600/600], d_loss [0.0286 : 0.0022], g_loss : 6.3368\n","Epoch [20/1000], Step [200/600], d_loss [0.0014 : 0.0018], g_loss : 7.0088\n","Epoch [20/1000], Step [400/600], d_loss [0.0020 : 0.0063], g_loss : 6.7835\n","Epoch [20/1000], Step [600/600], d_loss [0.0131 : 0.0107], g_loss : 5.3914\n","Epoch [21/1000], Step [200/600], d_loss [0.0343 : 0.0080], g_loss : 5.1688\n","Epoch [21/1000], Step [400/600], d_loss [0.0012 : 0.0012], g_loss : 6.7494\n","Epoch [21/1000], Step [600/600], d_loss [0.0015 : 0.0026], g_loss : 5.9882\n","Epoch [22/1000], Step [200/600], d_loss [0.0290 : 0.0003], g_loss : 7.1141\n","Epoch [22/1000], Step [400/600], d_loss [0.0164 : 0.0006], g_loss : 7.7281\n","Epoch [22/1000], Step [600/600], d_loss [0.3457 : 0.0309], g_loss : 4.5304\n","Epoch [23/1000], Step [200/600], d_loss [0.0151 : 0.0395], g_loss : 3.3508\n","Epoch [23/1000], Step [400/600], d_loss [0.0071 : 0.0037], g_loss : 5.2044\n","Epoch [23/1000], Step [600/600], d_loss [0.0016 : 0.0028], g_loss : 6.4421\n","Epoch [24/1000], Step [200/600], d_loss [0.0020 : 0.0133], g_loss : 5.7078\n","Epoch [24/1000], Step [400/600], d_loss [0.1503 : 0.0177], g_loss : 4.9591\n","Epoch [24/1000], Step [600/600], d_loss [0.0033 : 0.0223], g_loss : 4.7365\n","Epoch [25/1000], Step [200/600], d_loss [0.0497 : 0.0072], g_loss : 6.2498\n","Epoch [25/1000], Step [400/600], d_loss [0.0060 : 0.0104], g_loss : 6.1178\n","Epoch [25/1000], Step [600/600], d_loss [0.0019 : 0.0166], g_loss : 3.4100\n","Epoch [26/1000], Step [200/600], d_loss [0.0203 : 0.0009], g_loss : 7.6921\n","Epoch [26/1000], Step [400/600], d_loss [0.0317 : 0.0008], g_loss : 6.6104\n","Epoch [26/1000], Step [600/600], d_loss [0.0054 : 0.0009], g_loss : 6.7077\n","Epoch [27/1000], Step [200/600], d_loss [0.0240 : 0.0008], g_loss : 6.8797\n","Epoch [27/1000], Step [400/600], d_loss [0.0150 : 0.0029], g_loss : 6.1802\n","Epoch [27/1000], Step [600/600], d_loss [0.0033 : 0.0029], g_loss : 5.7431\n","Epoch [28/1000], Step [200/600], d_loss [0.0450 : 0.0011], g_loss : 6.9256\n","Epoch [28/1000], Step [400/600], d_loss [0.0009 : 0.0094], g_loss : 7.0985\n","Epoch [28/1000], Step [600/600], d_loss [0.0028 : 0.0015], g_loss : 6.2175\n","Epoch [29/1000], Step [200/600], d_loss [0.0095 : 0.0008], g_loss : 8.8647\n","Epoch [29/1000], Step [400/600], d_loss [0.0004 : 0.0226], g_loss : 4.4803\n","Epoch [29/1000], Step [600/600], d_loss [0.0062 : 0.0289], g_loss : 4.8972\n","Epoch [30/1000], Step [200/600], d_loss [0.0073 : 0.0166], g_loss : 6.2250\n","Epoch [30/1000], Step [400/600], d_loss [0.0045 : 0.0064], g_loss : 5.2591\n","Epoch [30/1000], Step [600/600], d_loss [0.0054 : 0.0012], g_loss : 5.8031\n","Epoch [31/1000], Step [200/600], d_loss [0.0012 : 0.0016], g_loss : 7.8656\n","Epoch [31/1000], Step [400/600], d_loss [0.0006 : 0.0012], g_loss : 6.6297\n","Epoch [31/1000], Step [600/600], d_loss [0.0082 : 0.0064], g_loss : 3.8964\n","Epoch [32/1000], Step [200/600], d_loss [0.0045 : 0.0477], g_loss : 3.2523\n","Epoch [32/1000], Step [400/600], d_loss [0.0010 : 0.0004], g_loss : 5.1705\n","Epoch [32/1000], Step [600/600], d_loss [0.0008 : 0.0018], g_loss : 7.1055\n","Epoch [33/1000], Step [200/600], d_loss [0.0156 : 0.0007], g_loss : 7.0123\n","Epoch [33/1000], Step [400/600], d_loss [0.0042 : 0.0026], g_loss : 9.2219\n","Epoch [33/1000], Step [600/600], d_loss [0.0095 : 0.0141], g_loss : 3.5150\n","Epoch [34/1000], Step [200/600], d_loss [0.0030 : 0.0184], g_loss : 4.9787\n","Epoch [34/1000], Step [400/600], d_loss [0.0077 : 0.0039], g_loss : 7.6578\n","Epoch [34/1000], Step [600/600], d_loss [0.0005 : 0.0026], g_loss : 6.4808\n","Epoch [35/1000], Step [200/600], d_loss [0.0069 : 0.0019], g_loss : 7.2271\n","Epoch [35/1000], Step [400/600], d_loss [0.0012 : 0.0011], g_loss : 7.1493\n","Epoch [35/1000], Step [600/600], d_loss [0.0979 : 0.0000], g_loss : 10.8096\n","Epoch [36/1000], Step [200/600], d_loss [0.0019 : 0.0009], g_loss : 5.5043\n","Epoch [36/1000], Step [400/600], d_loss [0.0005 : 0.0005], g_loss : 8.4125\n","Epoch [36/1000], Step [600/600], d_loss [0.0034 : 0.0001], g_loss : 7.2986\n","Epoch [37/1000], Step [200/600], d_loss [0.0064 : 0.0003], g_loss : 7.9679\n","Epoch [37/1000], Step [400/600], d_loss [0.0151 : 0.0067], g_loss : 6.7774\n","Epoch [37/1000], Step [600/600], d_loss [0.0003 : 0.0272], g_loss : 4.8780\n","Epoch [38/1000], Step [200/600], d_loss [0.1090 : 0.0230], g_loss : 6.1003\n","Epoch [38/1000], Step [400/600], d_loss [0.0053 : 0.0027], g_loss : 7.4597\n","Epoch [38/1000], Step [600/600], d_loss [0.0062 : 0.0054], g_loss : 6.7810\n","Epoch [39/1000], Step [200/600], d_loss [0.0030 : 0.0009], g_loss : 7.2872\n","Epoch [39/1000], Step [400/600], d_loss [0.0002 : 0.0028], g_loss : 7.8409\n","Epoch [39/1000], Step [600/600], d_loss [0.0417 : 0.0177], g_loss : 6.9446\n","Epoch [40/1000], Step [200/600], d_loss [0.0097 : 0.0033], g_loss : 8.0828\n","Epoch [40/1000], Step [400/600], d_loss [0.0024 : 0.0042], g_loss : 7.9499\n","Epoch [40/1000], Step [600/600], d_loss [0.0007 : 0.0035], g_loss : 6.2563\n","Epoch [41/1000], Step [200/600], d_loss [0.0009 : 0.0005], g_loss : 7.0943\n","Epoch [41/1000], Step [400/600], d_loss [0.0059 : 0.0008], g_loss : 7.8515\n","Epoch [41/1000], Step [600/600], d_loss [0.0001 : 0.0044], g_loss : 4.6820\n","Epoch [42/1000], Step [200/600], d_loss [0.0020 : 0.0018], g_loss : 5.0361\n","Epoch [42/1000], Step [400/600], d_loss [0.0022 : 0.0099], g_loss : 7.3169\n","Epoch [42/1000], Step [600/600], d_loss [0.0023 : 0.0077], g_loss : 6.7946\n","Epoch [43/1000], Step [200/600], d_loss [0.0019 : 0.0002], g_loss : 8.7416\n","Epoch [43/1000], Step [400/600], d_loss [0.0003 : 0.0438], g_loss : 7.2139\n","Epoch [43/1000], Step [600/600], d_loss [0.0030 : 0.0004], g_loss : 8.2820\n","Epoch [44/1000], Step [200/600], d_loss [0.0046 : 0.0027], g_loss : 6.8211\n","Epoch [44/1000], Step [400/600], d_loss [0.0010 : 0.0007], g_loss : 4.1142\n","Epoch [44/1000], Step [600/600], d_loss [0.0020 : 0.0048], g_loss : 6.1204\n","Epoch [45/1000], Step [200/600], d_loss [0.0010 : 0.0046], g_loss : 6.2155\n","Epoch [45/1000], Step [400/600], d_loss [0.0012 : 0.0016], g_loss : 7.3673\n","Epoch [45/1000], Step [600/600], d_loss [0.0006 : 0.0025], g_loss : 6.1164\n","Epoch [46/1000], Step [200/600], d_loss [0.0008 : 0.0008], g_loss : 6.5498\n","Epoch [46/1000], Step [400/600], d_loss [0.0077 : 0.0009], g_loss : 4.0923\n","Epoch [46/1000], Step [600/600], d_loss [0.0006 : 0.0017], g_loss : 8.7046\n","Epoch [47/1000], Step [200/600], d_loss [0.0004 : 0.0117], g_loss : 6.6740\n","Epoch [47/1000], Step [400/600], d_loss [0.0026 : 0.0014], g_loss : 6.5116\n","Epoch [47/1000], Step [600/600], d_loss [0.0001 : 0.0052], g_loss : 4.8971\n","Epoch [48/1000], Step [200/600], d_loss [0.0032 : 0.0048], g_loss : 6.5881\n","Epoch [48/1000], Step [400/600], d_loss [0.0007 : 0.0338], g_loss : 3.8354\n","Epoch [48/1000], Step [600/600], d_loss [0.0029 : 0.0022], g_loss : 5.0555\n","Epoch [49/1000], Step [200/600], d_loss [0.0044 : 0.0004], g_loss : 9.5228\n","Epoch [49/1000], Step [400/600], d_loss [0.0078 : 0.0223], g_loss : 3.4593\n","Epoch [49/1000], Step [600/600], d_loss [0.0307 : 0.0009], g_loss : 8.2768\n","Epoch [50/1000], Step [200/600], d_loss [0.0015 : 0.0005], g_loss : 6.5755\n","Epoch [50/1000], Step [400/600], d_loss [0.0010 : 0.0007], g_loss : 7.4287\n","Epoch [50/1000], Step [600/600], d_loss [0.0013 : 0.0005], g_loss : 6.6237\n","Epoch [51/1000], Step [200/600], d_loss [0.0026 : 0.0000], g_loss : 12.5308\n","Epoch [51/1000], Step [400/600], d_loss [0.0022 : 0.0169], g_loss : 3.9258\n","Epoch [51/1000], Step [600/600], d_loss [0.0076 : 0.0028], g_loss : 3.2667\n","Epoch [52/1000], Step [200/600], d_loss [0.0009 : 0.0131], g_loss : 6.8967\n","Epoch [52/1000], Step [400/600], d_loss [0.0027 : 0.0054], g_loss : 7.2095\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-cad78a073f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"vPnJBpxGzCqL","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"n4lz8IN4zCsa","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"8c47Nik4zCvB","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"axSv5aJazCxd","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ugvSJ8LPzC0S","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"zW1ZPJSuzC2x","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vMkJGsWFzC4x","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}